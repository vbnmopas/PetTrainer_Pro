import os
import cv2
import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing.image import img_to_array
from ultralytics import YOLO
from tensorflow.keras.preprocessing.sequence import pad_sequences

# ğŸ“Œ 1ï¸âƒ£ COCO YOLOv5 ëª¨ë¸ ë¡œë“œ (ê°•ì•„ì§€ ê°ì§€ìš©)
yolo_model = YOLO("yolov5s.pt")  # COCO Pre-trained YOLO ëª¨ë¸

# ğŸ“Œ 2ï¸âƒ£ ê°•ì•„ì§€ í–‰ë™ ì¸ì‹ ëª¨ë¸ ë¡œë“œ
behavior_model = tf.keras.models.load_model("dog_behavior_model_v3.h5")  # í•™ìŠµí•œ ëª¨ë¸

# ğŸ“Œ 3ï¸âƒ£ ì´ë¯¸ì§€ ì‹œí€€ìŠ¤ ì „ì²˜ë¦¬ í•¨ìˆ˜
def preprocess_sequence(image_list, img_size=(64, 64), max_seq_length=30):
    sequence = []
    for img in image_list:
        img = cv2.resize(img, img_size)  # í¬ê¸° ì¡°ì •
        img_array = img_to_array(img) / 255.0  # ì •ê·œí™”
        sequence.append(img_array)

    sequence = pad_sequences([sequence], maxlen=max_seq_length, dtype='float32', padding='post', truncating='post', value=0)
    return np.array(sequence)

# ğŸ“Œ 4ï¸âƒ£ ê°•ì•„ì§€ í–‰ë™ ì¸ì‹ ì‹¤í–‰ í•¨ìˆ˜
def detect_dog_behavior(video_path):
    cap = cv2.VideoCapture(video_path)
    frame_list = []  # í–‰ë™ ë¶„ì„ì„ ìœ„í•œ í”„ë ˆì„ ì €ì¥

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        
        # ê°•ì•„ì§€ ê°ì§€
        results = yolo_model(frame)
        for result in results:
            boxes = result.boxes
            for box in boxes:
                if int(box.cls) == 16:  # COCOì—ì„œ "ê°•ì•„ì§€" í´ë˜ìŠ¤ ID (16)
                    x1, y1, x2, y2 = map(int, box.xyxy[0])
                    score = box.conf[0].item()  # ì‹ ë¢°ë„ ì ìˆ˜ ì¶”ì¶œ
                    dog_crop = frame[y1:y2, x1:x2]  # ê°•ì•„ì§€ ë¶€ë¶„ ì˜ë¼ë‚´ê¸°
                    
                    # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)  # ì´ˆë¡ìƒ‰ìœ¼ë¡œ ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
                    
                    # ê°•ì•„ì§€ ì‹ ë¢°ë„ í…ìŠ¤íŠ¸ ì¶”ê°€
                    label = f"Dog: {score:.2f}"  # ì‹ ë¢°ë„ í‘œì‹œ
                    cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

                    frame_list.append(dog_crop)

        # í–‰ë™ ë¶„ì„ í›„ í”„ë ˆì„ì— í…ìŠ¤íŠ¸ ì¶”ê°€
        if len(frame_list) > 0:
            input_sequence = preprocess_sequence(frame_list)
            prediction = behavior_model.predict(input_sequence)
            predicted_class = np.argmax(prediction)

            behavior = "SIT" if predicted_class == 0 else "BODYLOWER"
            cv2.putText(frame, f"Behavior: {behavior}", (20, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)  # í–‰ë™ í…ìŠ¤íŠ¸ ì¶”ê°€

        # í”„ë ˆì„ ì¶œë ¥
        cv2.imshow("Dog Behavior Detection", frame)

        # 'q'ë¥¼ ëˆŒëŸ¬ì„œ ë¹„ë””ì˜¤ë¥¼ ì¢…ë£Œ
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()

# ì‹¤í–‰ ì˜ˆì‹œ (í…ŒìŠ¤íŠ¸ìš© ì˜ìƒ íŒŒì¼ ê²½ë¡œ ì…ë ¥)
detect_dog_behavior("C:/testimage/sitDog5.mp4")
