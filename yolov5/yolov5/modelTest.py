
"""
from tensorflow.keras.models import load_model
import cv2
import numpy as np

# ì €ì¥ëœ ëª¨ë¸ ë¡œë“œ
model = load_model('dog_behavior_model.h5')

def preprocess_video(video_path, img_size=(64, 64), sequence_length=14):
    # ë¹„ë””ì˜¤ íŒŒì¼ ì—´ê¸°
    cap = cv2.VideoCapture(video_path)
    
    frames = []
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break  # ë¹„ë””ì˜¤ ëì— ë„ë‹¬
        
        # ì˜ìƒ í¬ê¸° ì¡°ì • ë° ëª¨ë¸ì— ë§ëŠ” í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        frame_resized = cv2.resize(frame, img_size)
        frame_array = np.array(frame_resized)
        frames.append(frame_array)
    
    cap.release()

    # ì˜ìƒ ì‹œí€€ìŠ¤ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
    frames = np.array(frames)

    # 14ê°œì˜ ì—°ì†ëœ í”„ë ˆì„ì„ í•˜ë‚˜ì˜ ì‹œí€€ìŠ¤ë¡œ ë¬¶ìŒ
    sequences = []
    for i in range(len(frames) - sequence_length + 1):
        sequences.append(frames[i:i + sequence_length])

    sequences = np.array(sequences)
    
    return sequences

# ì˜ˆì‹œ: ë¹„ë””ì˜¤ íŒŒì¼ì„ ì²˜ë¦¬í•˜ì—¬ í”„ë ˆì„ì„ ì–»ì–´ì˜´
video_path = 'C:/testimage/bodylowerDog.mp4'
video_frames = preprocess_video(video_path)
print(f"ì˜ìƒ í”„ë ˆì„ í¬ê¸°: {video_frames.shape}")
print(f"ì˜ìƒ í”„ë ˆì„ ê°’: {video_frames}")

# ì˜ˆì¸¡ ìˆ˜í–‰
predictions = model.predict(video_frames)

# ì˜ˆì¸¡ëœ í´ë˜ìŠ¤ í™•ì¸
for i, prediction in enumerate(predictions):
    predicted_class = np.argmax(prediction)  # 0: sit, 1: lying
    print(f"ì‹œí€€ìŠ¤ {i}ì—ì„œì˜ ì˜ˆì¸¡: {'ì•‰ê¸°' if predicted_class == 0 else 'ëˆ„ì›Œìˆê¸°'}")



import cv2
import numpy as np  # numpy ì„í¬íŠ¸

video_path = "C:/capstonimage/dog.bmp"  # ë¹„ë””ì˜¤ ê²½ë¡œ ì§€ì •
cap = cv2.VideoCapture(video_path)

if not cap.isOpened():
    print("ë¹„ë””ì˜¤ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
else:
    print("ë¹„ë””ì˜¤ íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì—´ë ¸ìŠµë‹ˆë‹¤.")

frames = []
while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break
    frames.append(frame)

cap.release()
frames = np.array(frames)
print(f"ì˜ìƒ í”„ë ˆì„ í¬ê¸°: {frames.shape}")
print(f"ì˜ìƒ í”„ë ˆì„ ê°’: {video_frames}")

"""
#í›ˆë ¨ ë°ì´í„° ì •í™•ë„: 1.0000, ì†ì‹¤: 0.0000
#ê²€ì¦ ë°ì´í„° ì •í™•ë„: 0.9744, ì†ì‹¤: 0.0475

"""
import os
import numpy as np
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv3D, MaxPooling3D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.model_selection import train_test_split

# ğŸŸ¢ ë°ì´í„° ë¡œë“œ í•¨ìˆ˜
def load_images_from_folder(folder, img_size=(64, 64)):
    images = []
    for filename in os.listdir(folder):
        if filename.endswith('.jpg') or filename.endswith('.png'):
            img_path = os.path.join(folder, filename)
            img = load_img(img_path, target_size=img_size)  # í¬ê¸° ì¡°ì •
            img_array = img_to_array(img)
            images.append(img_array)
    return images

def create_sequence_data(base_folder, img_size=(64, 64)):
    image_data = []
    labels = []
    max_seq_length = 0  # ê°€ì¥ ê¸´ ì‹œí€€ìŠ¤ ì°¾ê¸°

    for foldername, _, _ in os.walk(base_folder):
        label_file = os.path.join(foldername, f"{os.path.basename(foldername)}.txt")
        if not os.path.exists(label_file):
            continue

        with open(label_file, 'r') as file:
            label = int(file.readline().strip().split()[0])  # ì²« ë²ˆì§¸ ê°’ì„ ë ˆì´ë¸”ë¡œ ì‚¬ìš©

        images = load_images_from_folder(foldername, img_size=img_size)
        max_seq_length = max(max_seq_length, len(images))

        if len(images) > 0:
            image_data.append(images)
            labels.append(label)

    if len(image_data) == 0:
        print("í›ˆë ¨ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„° ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return np.array([]), np.array([])

    # íŒ¨ë”© ì ìš©
    image_data = pad_sequences(image_data, maxlen=max_seq_length, dtype='float32', padding='post', truncating='post', value=0)
    labels = np.array(labels)

    return image_data, labels

# ğŸŸ¢ ë°ì´í„° ë¡œë“œ ë° ë¶„í• 
dataset_path = "C:/PetTrainer_Pro/yolov5/yolov5/data/dataset_dog/labels"
train_data, train_labels = create_sequence_data(dataset_path)

# ë°ì´í„° ë¶„í•  (í›ˆë ¨:ê²€ì¦ = 8:2)
x_train, x_val, y_train, y_val = train_test_split(train_data, train_labels, test_size=0.2, random_state=42)

# í´ë˜ìŠ¤ ë¶„í¬ ì¶œë ¥
unique, counts = np.unique(y_train, return_counts=True)
print(f"í›ˆë ¨ ë°ì´í„° ë¶„í¬: {dict(zip(unique, counts))}")

unique, counts = np.unique(y_val, return_counts=True)
print(f"ê²€ì¦ ë°ì´í„° ë¶„í¬: {dict(zip(unique, counts))}")

# ğŸŸ¢ ëª¨ë¸ ì •ì˜
model = Sequential()

# Conv3D Layer 1
model.add(Conv3D(32, kernel_size=(3, 3, 3), activation='relu', input_shape=(x_train.shape[1], 64, 64, 3)))
model.add(MaxPooling3D(pool_size=(2, 2, 2)))
model.add(BatchNormalization())  # ë°°ì¹˜ ì •ê·œí™” ì ìš©
model.add(Dropout(0.3))

# Conv3D Layer 2
model.add(Conv3D(64, kernel_size=(3, 3, 3), activation='relu'))
model.add(MaxPooling3D(pool_size=(2, 2, 2)))
model.add(BatchNormalization())
model.add(Dropout(0.4))

# Flatten Layer
model.add(Flatten())

# Dense Layer
model.add(Dense(128, activation='relu'))  # 64 â†’ 128 ë³€ê²½
model.add(Dropout(0.5))

# Output Layer (2 classes: Sitting or Lying)
model.add(Dense(2, activation='softmax'))

# ğŸŸ¢ ëª¨ë¸ ì»´íŒŒì¼ (í•™ìŠµë¥  0.0003 ì¡°ì •)
model.compile(optimizer=Adam(learning_rate=0.0003), loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# ëª¨ë¸ ìš”ì•½
model.summary()

# ğŸŸ¢ Early Stopping ì„¤ì •
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

# ğŸŸ¢ ëª¨ë¸ í•™ìŠµ
history = model.fit(x_train, y_train, epochs=30, batch_size=32, validation_data=(x_val, y_val), callbacks=[early_stopping])

# í•™ìŠµ ê³¼ì • ì¶œë ¥
print(history.history)

# ğŸŸ¢ ëª¨ë¸ í‰ê°€
train_loss, train_acc = model.evaluate(x_train, y_train)
val_loss, val_acc = model.evaluate(x_val, y_val)

print(f"í›ˆë ¨ ë°ì´í„° ì •í™•ë„: {train_acc:.4f}, ì†ì‹¤: {train_loss:.4f}")
print(f"ê²€ì¦ ë°ì´í„° ì •í™•ë„: {val_acc:.4f}, ì†ì‹¤: {val_loss:.4f}")

# ëª¨ë¸ ì €ì¥
model.save('dog_behavior_model.h5')
"""

import cv2
import numpy as np
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import img_to_array
from collections import deque  # ì‹œí€€ìŠ¤ ë°ì´í„°ë¥¼ ì €ì¥í•  í

# ğŸ“Œ ëª¨ë¸ ë¡œë“œ

# ğŸ“Œ í´ë˜ìŠ¤ ë¼ë²¨ (0: ì•‰ê¸°, 1: ëˆ•ê¸°)
class_labels = {0: "Sitting", 1: "Lying"}

# ğŸ“Œ ì›¹ìº  ì—´ê¸° (0: ê¸°ë³¸ ì¹´ë©”ë¼)
cap = cv2.VideoCapture(0)

# ğŸ“Œ ì‹œí€€ìŠ¤ ë°ì´í„°ë¥¼ ì €ì¥í•  í (ìµœê·¼ 14ê°œ í”„ë ˆì„ ì €ì¥)q
frame_sequence = deque(maxlen=14)

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        print("âŒ ì¹´ë©”ë¼ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        break

    # ğŸ“Œ í”„ë ˆì„ í¬ê¸° ì¡°ì • (64x64ë¡œ ë³€ê²½)
    img = cv2.resize(frame, (64, 64))
    img = img_to_array(img).astype('float32') / 255.0  # ì •ê·œí™”
    frame_sequence.append(img)  # ì‹œí€€ìŠ¤ì— ì¶”ê°€

    # ğŸ“Œ 14ê°œ í”„ë ˆì„ì´ ëª¨ì´ë©´ ì˜ˆì¸¡ ìˆ˜í–‰
    if len(frame_sequence) == 14:
        input_data = np.expand_dims(np.array(frame_sequence), axis=0)  # (1, 14, 64, 64, 3)
        prediction = model.predict(input_data)

        # ğŸ“Œ ì˜ˆì¸¡ê°’ í™•ì¸
        class_idx = np.argmax(prediction[0])  # ê°€ì¥ ë†’ì€ í™•ë¥ ì„ ê°€ì§„ í´ë˜ìŠ¤ì˜ ì¸ë±ìŠ¤
        class_name = class_labels[class_idx]

        print(f"ğŸ” ì˜ˆì¸¡ í™•ë¥ ê°’: {prediction[0]}")
        print(f"ğŸ¯ ì˜ˆì¸¡ í´ë˜ìŠ¤ ì¸ë±ìŠ¤: {class_idx}, í´ë˜ìŠ¤ëª…: {class_name}")

        # ğŸ“Œ ì˜ìƒì— ê²°ê³¼ í‘œì‹œ (ë…¸ë€ìƒ‰)
        cv2.putText(frame, class_name, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)

    cv2.imshow("Dog Behavior Detection - Real-time", frame)

    # 'q' í‚¤ë¥¼ ëˆ„ë¥´ë©´ ì¢…ë£Œ
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()


