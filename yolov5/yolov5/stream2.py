import cv2
import numpy as np
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import img_to_array
from collections import deque
from tensorflow.keras.preprocessing.sequence import pad_sequences
from ultralytics import YOLO
from flask import Flask, Response

app = Flask(__name__)

# ğŸ“Œ ì›¹ìº  ìŠ¤íŠ¸ë¦¬ë° ì£¼ì†Œ (MJPEG ìŠ¤íŠ¸ë¦¬ë° URL)
# IP_CAMERA_URL = "http://192.168.180.228:8080/video"  # MJPEG ìŠ¤íŠ¸ë¦¬ë° ê²½ë¡œ
IP_CAMERA_URL = cv2.VideoCapture(0)


# ğŸ“Œ YOLO ëª¨ë¸ (ê°•ì•„ì§€ ê°ì§€ìš©)
yolo_model = YOLO("yolov5s.pt")  # COCO Pre-trained YOLO ëª¨ë¸

# ğŸ“Œ ê°•ì•„ì§€ í–‰ë™ ì¸ì‹ ëª¨ë¸
behavior_model = load_model("dog_behavior_model_v2.h5")

# ğŸ“Œ í´ë˜ìŠ¤ ë¼ë²¨ (0: ì•‰ê¸°, 1: ëˆ•ê¸°)
class_labels = {0: "Sitting", 1: "BodyLower"}

# ğŸ“Œ ì›¹ìº  ì—´ê¸° (MJPEG ìŠ¤íŠ¸ë¦¬ë° URL)
cap = cv2.VideoCapture(IP_CAMERA_URL)

# ğŸ“Œ ì‹œí€€ìŠ¤ ë°ì´í„°ë¥¼ ì €ì¥í•  í (ìµœê·¼ 14ê°œ í”„ë ˆì„ ì €ì¥)
frame_sequence = deque(maxlen=14)
frame_buffer = deque(maxlen=30)  # ê°•ì•„ì§€ ì˜ì—­ì„ ìœ„í•œ ë²„í¼

def preprocess_sequence(image_list, img_size=(64, 64), max_seq_length=30):
    sequence = [cv2.resize(img, img_size) / 255.0 for img in image_list]
    sequence = pad_sequences([sequence], maxlen=max_seq_length, dtype='float32', padding='post', truncating='post', value=0)
    return np.array(sequence)

def generate_frames():
    while True:
        success, frame = cap.read()  # MJPEG ìŠ¤íŠ¸ë¦¬ë°ì—ì„œ í”„ë ˆì„ ì½ê¸°
        if not success:
            break

        # ğŸ“Œ YOLOë¡œ ê°•ì•„ì§€ ê°ì§€
        results = yolo_model(frame)
        dog_detected = False  # ê°•ì•„ì§€ê°€ ê°ì§€ë˜ì—ˆëŠ”ì§€ ì—¬ë¶€ë¥¼ ì¶”ì 

        for result in results:
            for box in result.boxes:
                if int(box.cls) == 16:  # COCOì—ì„œ ê°•ì•„ì§€ í´ë˜ìŠ¤ ID (16ì€ ê°•ì•„ì§€)
                    x1, y1, x2, y2 = map(int, box.xyxy[0])
                    dog_crop = frame[y1:y2, x1:x2]  # ê°•ì•„ì§€ ì˜ì—­ ìë¥´ê¸°
                    frame_buffer.append(dog_crop)
                    dog_detected = True  # ê°•ì•„ì§€ê°€ ê°ì§€ë˜ì—ˆìŒì„ í‘œì‹œ

                    # ğŸ“Œ ê°•ì•„ì§€ ì˜ì—­ì— ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)  # ì´ˆë¡ìƒ‰ ë°•ìŠ¤

        # ğŸ“Œ ê°•ì•„ì§€ê°€ ê°ì§€ë˜ì—ˆì„ ê²½ìš°ì—ë§Œ í–‰ë™ ì˜ˆì¸¡ ìˆ˜í–‰
        if dog_detected and len(frame_buffer) == 30:  # 30ê°œ í”„ë ˆì„ì´ ëª¨ì´ë©´ ì˜ˆì¸¡ ìˆ˜í–‰
            input_sequence = preprocess_sequence(list(frame_buffer))
            prediction = behavior_model.predict(input_sequence)
            predicted_class = np.argmax(prediction)  # 0 = ì•‰ê¸°, 1 = ëˆ•ê¸°

            # ì˜ˆì¸¡ëœ í–‰ë™
            behavior = class_labels[predicted_class]

            # ğŸ“Œ í–‰ë™ í…ìŠ¤íŠ¸ í‘œì‹œ
            cv2.putText(frame, behavior, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 255), 2)

        # ğŸ“Œ ê°•ì•„ì§€ê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ë‹¤ë©´ í–‰ë™ ì¸ì‹ì„ í•˜ì§€ ì•ŠìŒ
        elif not dog_detected:
            cv2.putText(frame, "No dog detected", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)

        # ğŸ“Œ í”„ë ˆì„ì„ JPEGë¡œ ì¸ì½”ë”© í›„ ìŠ¤íŠ¸ë¦¬ë°
        _, buffer = cv2.imencode('.jpg', frame)
        frame = buffer.tobytes()
        yield (b'--frame\r\n'
               b'Content-Type: image/jpeg\r\n\r\n' + frame + b'\r\n')

@app.route('/video')
def video_feed():
    return Response(generate_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')

if __name__ == "__main__":
    app.run(host='192.168.0.23', port=5000, debug=False)
